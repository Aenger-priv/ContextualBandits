{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-paper')  \n",
    "\n",
    "sns.set_context(\"paper\")  \n",
    "plt.rcParams['figure.figsize'] = (10, 6)  \n",
    "plt.rcParams['savefig.dpi'] = 300  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our custom modules\n",
    "from bandit_algorithms import LinUCB, SlidingWindowLinUCB,LinUCBDecay, LinTS, EpsilonGreedy, SlidingDoublyRobustSoftmax, RidgeSoftmax\n",
    "from bandit_experiment import BanditExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "def load_data(file_path='fx_trading_dataset.json'):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Let's examine the data first\n",
    "data = load_data()\n",
    "print(f\"Dataset contains {len(data)} trade instances\")\n",
    "print(f\"First data entry: {data[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "currency_pairs = set([d['context']['currency_pair'] for d in data])\n",
    "dates = set([d['context']['date'] for d in data])\n",
    "times_of_day = set([d['context']['time_of_day'] for d in data])\n",
    "\n",
    "print(f\"Unique currency pairs: {currency_pairs}\")\n",
    "print(f\"Number of unique dates: {len(dates)}\")\n",
    "print(f\"Unique times of day: {times_of_day}\")\n",
    "\n",
    "# How many arms/strategies are available?\n",
    "n_arms = len(data[0]['rewards'])\n",
    "print(f\"Number of arms/strategies: {n_arms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for running single algorithms for inspecting hyperparamterer sensitivity\n",
    "\n",
    "experiment = BanditExperiment(data)\n",
    "\n",
    "experiment.add_algorithm(LinUCBDecay, alpha=0.4, decay=0.99985)\n",
    "\n",
    "print(\"Running experiment...\")\n",
    "results = experiment.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up and run the experiment\n",
    "experiment = BanditExperiment(data)\n",
    "\n",
    "# Add algorithms with different parameters\n",
    "experiment.add_algorithm(LinUCB, alpha=0.25)\n",
    "experiment.add_algorithm(SlidingWindowLinUCB, alpha=0.25, window_size=500)\n",
    "experiment.add_algorithm(LinUCBDecay, alpha= 0.25, decay=0.99985)\n",
    "experiment.add_algorithm(LinTS, v=0.025)\n",
    "experiment.add_algorithm(EpsilonGreedy, epsilon=0.025)\n",
    "experiment.add_algorithm(SlidingDoublyRobustSoftmax, tau=0.025, window_size=500)\n",
    "experiment.add_algorithm(RidgeSoftmax, tau = 0.025)\n",
    "# Run the experiment\n",
    "print(\"Running experiment...\")\n",
    "results = experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For selection logs:\n",
    "\n",
    "selection_log = experiment.algorithms[5].selection_log_df\n",
    "experiment.algorithms[5].selection_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For update logs:\n",
    "update_log = experiment.algorithms[5].update_log_df\n",
    "#offset the update log by 1 step so it starts with 0\n",
    "update_log['step'] = update_log['step'] - 1\n",
    "update_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_log = pd.merge(selection_log, update_log, on='step', how='outer')\n",
    "merged_log.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "\n",
    "## 1. Cumulative Reward Analysis\n",
    "experiment.plot_cumulative_rewards()\n",
    "plt.title(\"Cumulative Reward Comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get the figure from the experiment\n",
    "fig = experiment.plot_cumulative_rewards()\n",
    "\n",
    "# Then modify the current axes\n",
    "ax = plt.gca()  # Get current axes\n",
    "\n",
    "# Set x-axis limits to show only last 3000 steps\n",
    "total_steps = len(experiment.results[list(experiment.results.keys())[0]]['cumulative_rewards'])\n",
    "ax.set_xlim(total_steps - 365, total_steps)\n",
    "\n",
    "# Calculate y-axis limits based only on actual algorithm rewards for the last 3000 steps\n",
    "y_min = min(min(result['cumulative_rewards'][-700:]) for result in experiment.results.values())\n",
    "y_max = max(max(result['cumulative_rewards'][-700:]) for result in experiment.results.values())\n",
    "y_range = y_max - y_min\n",
    "padding = y_range * 0.1  # 10% padding\n",
    "\n",
    "# Set y-axis limits\n",
    "ax.set_ylim(y_min - padding, y_max + padding)\n",
    "\n",
    "# Add more grid lines\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# Update the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Cumulative Regret Analysis\n",
    "experiment.plot_cumulative_regrets()\n",
    "plt.title(\"Cumulative Regret Comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Arm Selection Distribution\n",
    "experiment.plot_arm_selection_frequencies()\n",
    "plt.suptitle(\"Arm Selection Frequencies by Algorithm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Arm Selection Over Time\n",
    "#experiment.plot_arm_selections_over_time()\n",
    "#plt.suptitle(\"Arm Selections Over Time\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Summary Statistics\n",
    "summary_stats = experiment.print_summary_statistics()\n",
    "print(\"Summary Statistics:\")\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Statistical Significance Testing\n",
    "test_results, pairwise_comparisons = experiment.statistical_tests()\n",
    "print(\"ANOVA Results:\")\n",
    "print(test_results)\n",
    "if pairwise_comparisons is not None:\n",
    "    print(\"\\nPairwise Comparisons (Tukey's HSD):\")\n",
    "    pairwise_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_algorithm_summaries(experiment):\n",
    "    \n",
    "    # Create a dictionary to store stats\n",
    "    stats = {}\n",
    "    \n",
    "    for algo_name, result in experiment.results.items():\n",
    "        rewards = result['obtained_rewards']\n",
    "        stats[algo_name] = {\n",
    "            'Mean Reward': np.mean(rewards),\n",
    "            'Median Reward': np.median(rewards),\n",
    "            'Std Dev': np.std(rewards),\n",
    "            'Min Reward': np.min(rewards),\n",
    "            'Max Reward': np.max(rewards),\n",
    "            '25th Percentile': np.percentile(rewards, 25),\n",
    "            '75th Percentile': np.percentile(rewards, 75),\n",
    "            'Final Cumulative Reward': result['cumulative_rewards'][-1],\n",
    "            'Final Cumulative Regret': result['cumulative_regrets'][-1]\n",
    "        }\n",
    "    \n",
    "    # Convert to DataFrame for nice display\n",
    "    summary_df = pd.DataFrame(stats).T  # Transpose to have algorithms as rows\n",
    "    \n",
    "    # Add a regret per step metric\n",
    "    summary_df['Regret per Step'] = summary_df['Final Cumulative Regret'] / len(experiment.data)\n",
    "    \n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_results = show_algorithm_summaries(experiment)\n",
    "display(pairwise_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Non-stationarity Adaptation Analysis\n",
    "adaptation_metrics = experiment.calculate_adaptation_metrics()\n",
    "if adaptation_metrics is not None:\n",
    "    print(\"Adaptation Metrics Around Regime Shifts:\")\n",
    "    adaptation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Cold Start Analysis\n",
    "cold_start_metrics = experiment.analyze_cold_start()\n",
    "if cold_start_metrics is not None and not cold_start_metrics.empty:\n",
    "    print(\"Cold Start Adaptation Metrics:\")\n",
    "    display(cold_start_metrics)\n",
    "\n",
    "    # Save to CSV\n",
    "    cold_start_metrics.to_csv(\"cold_start_metrics.csv\", index=False)\n",
    "    print(\"Saved cold start metrics to 'cold_start_metrics.csv'.\")\n",
    "else:\n",
    "    print(\"No cold start metrics returned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Unique currency pairs in dataset\n",
    "currency_pairs = sorted(list(set(d['context']['currency_pair'] for d in data)))\n",
    "\n",
    "# Set color palette (one per algorithm)\n",
    "palette = sns.color_palette(\"Set2\", n_colors=len(experiment.results))\n",
    "\n",
    "# Setup figure with better spacing\n",
    "fig = plt.figure(figsize=(16, 4 * len(experiment.results)), constrained_layout=True)\n",
    "gs = gridspec.GridSpec(len(experiment.results), 1, figure=fig)\n",
    "\n",
    "for i, (algo_name, result) in enumerate(experiment.results.items()):\n",
    "    ax = fig.add_subplot(gs[i])\n",
    "    \n",
    "    # Organize data for seaborn violinplot\n",
    "    plot_data = []\n",
    "    plot_labels = []\n",
    "    \n",
    "    for j, entry in enumerate(data):\n",
    "        if j < len(result['obtained_rewards']):\n",
    "            cp = entry['context']['currency_pair']\n",
    "            reward = result['obtained_rewards'][j]\n",
    "            plot_data.append(reward)\n",
    "            plot_labels.append(cp)\n",
    "\n",
    "    # Create DataFrame for seaborn\n",
    "    df = pd.DataFrame({\n",
    "        'Reward': plot_data,\n",
    "        'Currency Pair': plot_labels\n",
    "    })\n",
    "\n",
    "    sns.violinplot(\n",
    "        data=df,\n",
    "        x='Currency Pair',\n",
    "        y='Reward',\n",
    "        ax=ax,\n",
    "        color=palette[i],       # one color per algorithm\n",
    "        inner='point',          # show mean/median points\n",
    "        width=0.9               # make violins wider\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f\"{algo_name} - Reward Distribution by Currency Pair\", fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Reward')\n",
    "    ax.tick_params(axis='x', rotation=30)  # rotate x labels for clarity\n",
    "\n",
    "# Tighten layout before adding title\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.92)  # reduce space between suptitle and plots\n",
    "plt.suptitle(\"Reward Distributions per Algorithm by Currency Pair\", fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "print(\"Violin plots complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
